{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame the problem:\n",
    "\"describe the dataset, the purpose and aim of the project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading, descriptive stats, percentage split of each column so we can verify after splitting\n",
    "\"add comments for every aspect here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "df = pd.read_csv('churn.csv')\n",
    "# check the na values\n",
    "print('=isnull==========================================================')\n",
    "print(df.isnull().sum())\n",
    "# check the duplicate values\n",
    "print('=duplicated======================================================')\n",
    "print(df.duplicated().sum())\n",
    "# check the unique values\n",
    "print('=nunique=========================================================')\n",
    "print(df.nunique())\n",
    "# check the data types\n",
    "print('=dtypes=========================================================')\n",
    "print(df.dtypes)\n",
    "# check the data shape\n",
    "print('=if it is unbalance==============================================')\n",
    "print(\"not Exited 0 : \",df[df['Exited']==0].shape)\n",
    "print(\"Exited 1 : \",df[df['Exited']==1].shape)\n",
    "# check the overall data \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - train/test split\n",
    "\"It may sound strange to voluntarily set aside part of the data at this stage. After all, you have only taken a quick glance at the data, and surely you should learn a whole lot more about it before you decide what algorithms to use, right? This is true, but your brain is an amazing pattern detection system, which means that it is highly prone to overfitting: if you look at the test set, you may stumble upon some seemingly interesting pattern in the test data that leads you to select a particular kind of Machine Learning model. When you estimate the generalization error using the test set, your estimate will be too optimistic and you will launch a system that will not perform as well as expected. This is called data snooping bias.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here need to change to George's code to evenly distribute the 0 an 1\n",
    "y = df['Exited'] # 1 in the case of Exited; 0 not Exited\n",
    "X = df.drop(columns='Exited')\n",
    "\n",
    "# split training, validation and test sets\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, y, train_size=0.75, random_state=461)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_val, Y_train_val, train_size = 0.8, random_state=461)\n",
    "print(X_train.shape, X_valid.shape , X_test.shape)\n",
    "\n",
    "numeric_columns = [\n",
    "    'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'EstimatedSalary'\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "X_valid[numeric_columns] = scaler.transform(X_valid[numeric_columns])\n",
    "X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and Descpritive study of training set (inc. viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlations, scatterplots, histograms, all of Tim's stuff, some of George's stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the preprocessing definiation function (just foor viz)\n",
    "def preprocesssing(df):    \n",
    "    # Drop the Surname, RowNumber, and CustomerId columns (no duplicates, all unique)\n",
    "    df.drop(columns=['Surname'],inplace=True)\n",
    "    df.drop(columns=['RowNumber'],inplace=True)\n",
    "    df.drop(columns=['CustomerId'],inplace=True)\n",
    "    #Make dummies from categroical variales\n",
    "    categorical_cols = [\n",
    "        'Geography', 'Gender'\n",
    "    ]\n",
    "    df = pd.get_dummies(df,\n",
    "                        columns=categorical_cols,\n",
    "                        dummy_na=False, # there's no nan in the df\n",
    "                        drop_first=True)\n",
    "    return df\n",
    "\n",
    "df = preprocesssing(df)\n",
    "\n",
    "# plotting the variable of 1 and 0 of distribution (after pre-processing)\n",
    "numeric_columns = [\n",
    "    'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'EstimatedSalary'\n",
    "]\n",
    "df_plot = df.copy()\n",
    "\n",
    "# see all the features differences of 0 and 1 with the mean (after preprocessing)\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    if i < 4:\n",
    "        sns.histplot(df_plot, x=f\"{col}\", hue = \"Exited\", kde=True, color=\"skyblue\", ax=axs[0, i])\n",
    "    else:\n",
    "        sns.histplot(df_plot, x=f\"{col}\", hue = \"Exited\", kde=True, color=\"skyblue\", ax=axs[1, i-4])\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "# Note rthat we take a look at the scalar data (but not really apply the scalar here, we should apply after the split\n",
    "scaler = StandardScaler()\n",
    "df_plot[numeric_columns] = scaler.fit_transform(df_plot[numeric_columns])\n",
    "# Plot out to see the mean of the data\n",
    "df_Exited_describe  = df_plot[df_plot['Exited']==1].describe()\n",
    "df_not_Exited_describe  = df_plot[df_plot['Exited']==0].describe()\n",
    "df_Exited_mean = df_Exited_describe.iloc[1:2]\n",
    "df_not_Exited_mean = df_not_Exited_describe.iloc[1:2]\n",
    "df_Exited_mean_transposed = df_Exited_mean.T \n",
    "df_not_Exite_mean_transposed = df_not_Exited_mean.T \n",
    "\n",
    "df_Exited_mean_transposed['variable'] = df_Exited_mean_transposed.index\n",
    "df_not_Exite_mean_transposed['variable'] = df_not_Exite_mean_transposed.index\n",
    "df_Exited_mean_transposed = df_Exited_mean_transposed.rename(columns={'mean': 'Exited mean'}, index={'variable': 'variable'})\n",
    "df_not_Exite_mean_transposed = df_not_Exite_mean_transposed.rename(columns={'mean': 'not Exited mean'}, index={'variable': 'variable'})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "ax = df_Exited_mean_transposed.plot(x='variable', y='Exited mean')\n",
    "df_not_Exite_mean_transposed.plot(ax=ax, x='variable', y='not Exited mean')\n",
    "\n",
    "plt.xticks(range(len(df_Exited_mean_transposed['variable'])),list(df_not_Exite_mean_transposed['variable']),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the numeric columns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "# Cheking the credit scores\n",
    "sns.histplot(df['CreditScore'], ax=axs[0,0])\n",
    "sns.boxplot(df['CreditScore'], ax=axs[0,1], color='orange')\n",
    "\n",
    "# Checking the Balance\n",
    "sns.histplot(df['Balance'], ax=axs[1,0])\n",
    "sns.boxplot(df['Balance'], ax=axs[1,1], color='orange')\n",
    "\n",
    "# Checking the Estimated salaries\n",
    "sns.histplot(df['Balance'], ax=axs[1,0])\n",
    "sns.boxplot(df['Balance'], ax=axs[1,1], color='orange')\n",
    "\n",
    "# Plotting the results\n",
    "sns.histplot(df['EstimatedSalary'], ax=axs[2,0])\n",
    "sns.boxplot(df['EstimatedSalary'], ax=axs[2,1], color='orange')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "## Finding for creditScore\n",
    "# Calculating the Z scores\n",
    "Z_credit = stats.zscore(df[\"CreditScore\"],nan_policy=\"omit\") #compute z-score table\n",
    "# Find the ones with Z scores out of the range [-3,3]\n",
    "print('Outliers at credit scores')\n",
    "print('=========================')\n",
    "print(np.where((Z_credit>3) | (Z_credit<-3)))\n",
    "\n",
    "\n",
    "## Finding for Balance\n",
    "# Calculating the Z scores\n",
    "Z_balance = stats.zscore(df[\"Balance\"],nan_policy=\"omit\") #compute z-score table\n",
    "# Find the ones with Z scores out of the range [-3,3]\n",
    "print('Outliers at Balance')\n",
    "print('===================')\n",
    "print(np.where((Z_balance>3) | (Z_balance<-3)))\n",
    "\n",
    "## Finding for Estimated salaries\n",
    "# Calculating the Z scores\n",
    "Z_salary = stats.zscore(df[\"EstimatedSalary\"],nan_policy=\"omit\") #compute z-score table\n",
    "# Find the ones with Z scores out of the range [-3,3]\n",
    "print('Outliers at Estimated Salary')\n",
    "print('============================')\n",
    "print(np.where((Z_salary>3) | (Z_salary<-3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "proving there is nothing to clean - just for the sake of including and evidencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here 's overlapping with the above\n",
    "# the preprocessing definiation function\n",
    "def preprocesssing(df):    \n",
    "    # Drop the Surname, RowNumber, and CustomerId columns (no duplicates, all unique)\n",
    "    df.drop(columns=['Surname'],inplace=True)\n",
    "    df.drop(columns=['RowNumber'],inplace=True)\n",
    "    df.drop(columns=['CustomerId'],inplace=True)\n",
    "    #Make dummies from categroical variales\n",
    "    categorical_cols = [\n",
    "        'Geography', 'Gender', 'IsActiveMember'\n",
    "    ]\n",
    "    df = pd.get_dummies(df,\n",
    "                        columns=categorical_cols,\n",
    "                        dummy_na=False, # there's no nan in the df\n",
    "                        drop_first=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering - try and do different things here (??Maybe do this after baseline models??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(defining a function to combine scaling, engineering, and categorcial dealing and to apply to the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Model\n",
    "Predict the majority class for each observation (George)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "Logistic Regression (Tim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic model on the training set\n",
    "logm_train = LogisticRegression(max_iter=2000).fit(X_train,Y_train.values.ravel()) \n",
    "print(\"Intercept = \",logm_train.intercept_)\n",
    "print(\"Model coefficients = \", logm_train.coef_)\n",
    "print(\"R^2 =\",logm_train.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use validation set to pick right threshold\n",
    "# fit the validation data to the trian model\n",
    "Y_probs =logm_train.predict_proba(X_valid)[:,1]\n",
    "# get the fpr tpr score\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_valid,Y_probs)\n",
    "plt.plot(fpr, tpr, linewidth=4)\n",
    "plt.show()\n",
    "#check the ROC score\n",
    "print('roc_auc_score',roc_auc_score(Y_valid,Y_probs))\n",
    "# get the threshold\n",
    "threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "print(\"Threshold = \",threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining the final model with training+validation\n",
    "train_val_X = pd.concat([X_train, X_valid])\n",
    "train_val_Y = pd.concat([Y_train, Y_valid])\n",
    "\n",
    "logm = LogisticRegression(max_iter=2000).fit(train_val_X, train_val_Y.values.ravel())\n",
    "print(\"Intercept = \",logm.intercept_)\n",
    "print(\"Model coefficients = \", logm.coef_)\n",
    "print(\"R^2 =\",logm.score(train_val_X, train_val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the accuracy of training + validation logistic model on the testing set\n",
    "# test dataset to check accuracy_score\n",
    "Y_probs_test =logm.predict_proba(X_test)[:,1]\n",
    "Y_pred_test = np.where(Y_probs_test > threshold, 1, 0) #imput the threshold\n",
    "cm = confusion_matrix(Y_test,Y_pred_test)\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "print(\"Accuracy = \",(TP+TN)/(TP+TN+FP+FN)) # or metrics.accuracy_score(Y_test,Y_pred_test)\n",
    "print(cm)\n",
    "\n",
    "# get the fpr tpr score\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test,Y_probs_test)\n",
    "plt.plot(fpr, tpr, linewidth=4)\n",
    "plt.show()\n",
    "#check the ROC score\n",
    "roc_auc_score(Y_test,Y_probs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers: SVM, DT, RF, kNN, Gradient Boosting Classifier\n",
    "\n",
    "SVM: Tim\\\n",
    "RF: Siyuan\\\n",
    "DT: Agam\\\n",
    "kNN: Tiana\\\n",
    "Gradient Boosting Classifier: George"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation: Everyone does it for their own models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recording Final Accuracies of Classifiers: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic FF NN (Tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean sessions and set seeds\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(231)\n",
    "tf.random.set_seed(631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorflow model\n",
    "model_benchmarking = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Dense(100, kernel_initializer = 'uniform',activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer = 'uniform',activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, kernel_initializer = 'uniform', activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "# early_stopping\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "# compile the model\n",
    "model_benchmarking.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics=[\"accuracy\"])\n",
    "# keep track of the perforance\n",
    "log = model_benchmarking.fit(X_train, Y_train, \n",
    "                epochs=200, \n",
    "                validation_data=(X_valid, Y_valid),\n",
    "               )\n",
    "\n",
    "print(\"MSE on test set: \" + str(model_benchmarking.evaluate(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise the lost \n",
    "plt.plot(log.history['loss'],label = \"training loss\")\n",
    "plt.plot(log.history['val_loss'], label = \"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalute the model on test set\n",
    "model_benchmarking.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter and layer size tuning - Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ??? Bias and Variance checking - Use different tools such as batch normalisation ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy comparison of NNs - choosing final NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies: Classifers vs NN "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0189003537ec2b8292d68d2da05924e65048cabd6480118674c404b3162677d9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ADL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c955ac2759b198ced90504fafd0653ff1948d23274faaeb8b6184240be651d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
